{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = os.getcwd()[:-len('scripts')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3881 1939 646\n"
     ]
    }
   ],
   "source": [
    "theia_dir = MAIN_DIR+\"dataset/gender/EnhancedUnbiasedDataset\"\n",
    "batch_size = 128\n",
    "\n",
    "train_transform = transforms.Compose([transforms.Resize(226),\n",
    "                                      transforms.RandomCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                      transforms.RandomRotation(10),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize(226),\n",
    "                                     transforms.RandomCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "theia_dataset = torchvision.datasets.ImageFolder(theia_dir, transform= train_transform)\n",
    "\n",
    "test = int(len(theia_dataset)*0.3)  \n",
    "valid = int(len(theia_dataset)*0.1)\n",
    "\n",
    "test_data = torch.utils.data.Subset(theia_dataset, range(test)) \n",
    "test_data.dataset.transform = test_transform\n",
    "\n",
    "valid_data = torch.utils.data.Subset(theia_dataset, range(test, test+valid))\n",
    "valid_data.dataset.transform = test_transform\n",
    "\n",
    "theia_data = torch.utils.data.Subset(theia_dataset, range(valid + test, len(theia_dataset)))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(theia_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size = batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size)\n",
    "\n",
    "print(len(theia_data), len(test_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\user/.cache\\torch\\hub\\pytorch_vision_master\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "num_classes = 2\n",
    "\n",
    "model_resnet18 = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
    "model_resnet18.fc = nn.Sequential(nn.Linear(model_resnet18.fc.in_features,512),\n",
    "                                  nn.ReLU(), nn.Dropout(), nn.Linear(512, num_classes))\n",
    "model_resnet18.load_state_dict(torch.load(MAIN_DIR+'checkpoints/gender/kaggle_model_best_96.pth.tar')['state_dict'])\n",
    "\n",
    "for name, param in model_resnet18.named_parameters():\n",
    "    if(\"bn\" not in name):\n",
    "        param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "# if GPU is available, move the model to GPU\n",
    "if train_on_gpu:\n",
    "    model_resnet18 = model_resnet18.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model_resnet18.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 20 loss: 0.6550118952989579\n",
      "Epoch 1, Batch 40 loss: 0.5730834305286407\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 4\n",
    "Train_loss = 0.0\n",
    "valid_loss = 0.0\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    # model by default is set to train\n",
    "    model_resnet18.train()\n",
    "    for batch_i, (data, target) in enumerate(train_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model_resnet18(data)\n",
    "        # calculate the batch loss\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        if batch_i % 20 == 19:    # print training loss every specified number of mini-batches\n",
    "            print('Epoch %d, Batch %d loss: %.16f' %\n",
    "                  (epoch, batch_i + 1, train_loss / 20))\n",
    "            Train_loss += train_loss/20\n",
    "            train_loss = 0.0\n",
    "\n",
    "        \n",
    "        #/////////////////////     Validation        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
    "        \n",
    "        model_resnet18.eval() # prep model for evaluation\n",
    "        for data, target in valid_loader:\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = model_resnet18(data)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # update running validation loss \n",
    "            valid_loss += loss.item()\n",
    "\n",
    "\n",
    "    # print training loss per epoch\n",
    "    print('Epoch %d, training loss: %.10f  validation loss : %.10f' %\n",
    "          (epoch, Train_loss, valid_loss/batch_i))\n",
    "    Train_loss = 0.0\n",
    "    valid_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Model\n",
    "torch.save(model_resnet18.state_dict(), 'checkpoints/gender/Enhanced_Model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.119744\n",
      "\n",
      "\n",
      "Test Accuracy (Overall): 0.861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0 \n",
    "total = 0\n",
    "correct = 0 \n",
    "topk=(1,)\n",
    "maxk = max(topk)\n",
    "model_resnet18.eval()\n",
    "for data, target in test_loader:\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    #data = data.repeat(1, 3, 1, 1)\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model_resnet18(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update  test loss \n",
    "    test_loss += loss.item()\n",
    "    _, predicted = torch.topk(output, 1)\n",
    "    total += target.size(0)\n",
    "    correct += (predicted == target.view(predicted.shape)).sum().item()\n",
    "    #correct += (predicted == target).sum().item()\n",
    "# calculate avg test loss\n",
    "test_loss = test_loss/batch_i\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "print('\\nTest Accuracy (Overall): {:.3f}\\n'.format(correct/total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
